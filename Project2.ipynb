{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78df5c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f41891",
   "metadata": {},
   "source": [
    "Loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8827dd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>DOY</th>\n",
       "      <th>SWin</th>\n",
       "      <th>SWout</th>\n",
       "      <th>LWin</th>\n",
       "      <th>LWout</th>\n",
       "      <th>Rr</th>\n",
       "      <th>Rn</th>\n",
       "      <th>RH</th>\n",
       "      <th>PPFD</th>\n",
       "      <th>...</th>\n",
       "      <th>(z-d)/L</th>\n",
       "      <th>T*</th>\n",
       "      <th>v_var</th>\n",
       "      <th>w/co2_cov</th>\n",
       "      <th>w/h2o_cov</th>\n",
       "      <th>w/ch4_cov</th>\n",
       "      <th>FCH4</th>\n",
       "      <th>Ta</th>\n",
       "      <th>Tc</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>15:00</td>\n",
       "      <td>131.6249</td>\n",
       "      <td>695.4</td>\n",
       "      <td>135.20</td>\n",
       "      <td>398.9</td>\n",
       "      <td>507.4</td>\n",
       "      <td>0.194</td>\n",
       "      <td>451.60</td>\n",
       "      <td>35.8238</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104409</td>\n",
       "      <td>-0.343706</td>\n",
       "      <td>1.337320</td>\n",
       "      <td>-0.004358</td>\n",
       "      <td>2.03306</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>300.282</td>\n",
       "      <td>308.48</td>\n",
       "      <td>2023-05-11 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>15:30</td>\n",
       "      <td>131.6457</td>\n",
       "      <td>506.8</td>\n",
       "      <td>96.70</td>\n",
       "      <td>392.3</td>\n",
       "      <td>497.4</td>\n",
       "      <td>0.187</td>\n",
       "      <td>305.10</td>\n",
       "      <td>35.3730</td>\n",
       "      <td>982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170200</td>\n",
       "      <td>-0.443938</td>\n",
       "      <td>1.958010</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>2.25563</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>300.194</td>\n",
       "      <td>306.58</td>\n",
       "      <td>2023-05-11 15:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>16:00</td>\n",
       "      <td>131.6665</td>\n",
       "      <td>319.4</td>\n",
       "      <td>60.97</td>\n",
       "      <td>395.8</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.190</td>\n",
       "      <td>177.00</td>\n",
       "      <td>35.6585</td>\n",
       "      <td>622.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099141</td>\n",
       "      <td>-0.290778</td>\n",
       "      <td>2.165070</td>\n",
       "      <td>-0.004225</td>\n",
       "      <td>1.91322</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>299.926</td>\n",
       "      <td>303.04</td>\n",
       "      <td>2023-05-11 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>16:30</td>\n",
       "      <td>131.6873</td>\n",
       "      <td>338.2</td>\n",
       "      <td>64.57</td>\n",
       "      <td>382.2</td>\n",
       "      <td>474.9</td>\n",
       "      <td>0.188</td>\n",
       "      <td>181.00</td>\n",
       "      <td>35.4072</td>\n",
       "      <td>632.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060258</td>\n",
       "      <td>-0.178902</td>\n",
       "      <td>1.145780</td>\n",
       "      <td>-0.001495</td>\n",
       "      <td>1.65756</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>300.065</td>\n",
       "      <td>302.43</td>\n",
       "      <td>2023-05-11 16:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>17:00</td>\n",
       "      <td>131.7082</td>\n",
       "      <td>121.5</td>\n",
       "      <td>22.22</td>\n",
       "      <td>377.4</td>\n",
       "      <td>456.5</td>\n",
       "      <td>0.184</td>\n",
       "      <td>20.15</td>\n",
       "      <td>36.9236</td>\n",
       "      <td>244.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060537</td>\n",
       "      <td>-0.161396</td>\n",
       "      <td>0.638123</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>1.20892</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.002318</td>\n",
       "      <td>299.410</td>\n",
       "      <td>299.08</td>\n",
       "      <td>2023-05-11 17:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time       DOY   SWin   SWout   LWin  LWout     Rr      Rn  \\\n",
       "date                                                                      \n",
       "2023-05-11  15:00  131.6249  695.4  135.20  398.9  507.4  0.194  451.60   \n",
       "2023-05-11  15:30  131.6457  506.8   96.70  392.3  497.4  0.187  305.10   \n",
       "2023-05-11  16:00  131.6665  319.4   60.97  395.8  477.3  0.190  177.00   \n",
       "2023-05-11  16:30  131.6873  338.2   64.57  382.2  474.9  0.188  181.00   \n",
       "2023-05-11  17:00  131.7082  121.5   22.22  377.4  456.5  0.184   20.15   \n",
       "\n",
       "                 RH    PPFD  ...   (z-d)/L        T*     v_var  w/co2_cov  \\\n",
       "date                         ...                                            \n",
       "2023-05-11  35.8238  1340.0  ... -0.104409 -0.343706  1.337320  -0.004358   \n",
       "2023-05-11  35.3730   982.0  ... -0.170200 -0.443938  1.958010  -0.006526   \n",
       "2023-05-11  35.6585   622.6  ... -0.099141 -0.290778  2.165070  -0.004225   \n",
       "2023-05-11  35.4072   632.8  ... -0.060258 -0.178902  1.145780  -0.001495   \n",
       "2023-05-11  36.9236   244.3  ... -0.060537 -0.161396  0.638123  -0.001278   \n",
       "\n",
       "            w/h2o_cov  w/ch4_cov      FCH4       Ta      Tc  \\\n",
       "date                                                          \n",
       "2023-05-11    2.03306  -0.000042 -0.002199  300.282  308.48   \n",
       "2023-05-11    2.25563  -0.000043  0.002734  300.194  306.58   \n",
       "2023-05-11    1.91322  -0.000033 -0.000904  299.926  303.04   \n",
       "2023-05-11    1.65756  -0.000024 -0.002743  300.065  302.43   \n",
       "2023-05-11    1.20892  -0.000020 -0.002318  299.410  299.08   \n",
       "\n",
       "                       datetime  \n",
       "date                             \n",
       "2023-05-11  2023-05-11 15:00:00  \n",
       "2023-05-11  2023-05-11 15:30:00  \n",
       "2023-05-11  2023-05-11 16:00:00  \n",
       "2023-05-11  2023-05-11 16:30:00  \n",
       "2023-05-11  2023-05-11 17:00:00  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data = pd.read_csv('/Users/kashyapava/Desktop/UIUC/SEM_4/STAT 430/Project 2/proj2_data_clean.csv',index_col='date', parse_dates=True)\n",
    "ts_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5e40c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOY</th>\n",
       "      <th>SWin</th>\n",
       "      <th>SWout</th>\n",
       "      <th>LWin</th>\n",
       "      <th>LWout</th>\n",
       "      <th>Rr</th>\n",
       "      <th>Rn</th>\n",
       "      <th>RH</th>\n",
       "      <th>PPFD</th>\n",
       "      <th>PPFDr</th>\n",
       "      <th>...</th>\n",
       "      <th>ET</th>\n",
       "      <th>(z-d)/L</th>\n",
       "      <th>T*</th>\n",
       "      <th>v_var</th>\n",
       "      <th>w/co2_cov</th>\n",
       "      <th>w/h2o_cov</th>\n",
       "      <th>w/ch4_cov</th>\n",
       "      <th>FCH4</th>\n",
       "      <th>Ta</th>\n",
       "      <th>Tc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>131.6249</td>\n",
       "      <td>695.4</td>\n",
       "      <td>135.20</td>\n",
       "      <td>398.9</td>\n",
       "      <td>507.4</td>\n",
       "      <td>0.194</td>\n",
       "      <td>451.60</td>\n",
       "      <td>35.8238</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>160.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159395</td>\n",
       "      <td>-0.104409</td>\n",
       "      <td>-0.343706</td>\n",
       "      <td>1.337320</td>\n",
       "      <td>-0.004358</td>\n",
       "      <td>2.03306</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>300.282</td>\n",
       "      <td>308.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>131.6457</td>\n",
       "      <td>506.8</td>\n",
       "      <td>96.70</td>\n",
       "      <td>392.3</td>\n",
       "      <td>497.4</td>\n",
       "      <td>0.187</td>\n",
       "      <td>305.10</td>\n",
       "      <td>35.3730</td>\n",
       "      <td>982.0</td>\n",
       "      <td>118.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178391</td>\n",
       "      <td>-0.170200</td>\n",
       "      <td>-0.443938</td>\n",
       "      <td>1.958010</td>\n",
       "      <td>-0.006526</td>\n",
       "      <td>2.25563</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>300.194</td>\n",
       "      <td>306.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>131.6665</td>\n",
       "      <td>319.4</td>\n",
       "      <td>60.97</td>\n",
       "      <td>395.8</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.190</td>\n",
       "      <td>177.00</td>\n",
       "      <td>35.6585</td>\n",
       "      <td>622.6</td>\n",
       "      <td>74.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147962</td>\n",
       "      <td>-0.099141</td>\n",
       "      <td>-0.290778</td>\n",
       "      <td>2.165070</td>\n",
       "      <td>-0.004225</td>\n",
       "      <td>1.91322</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>299.926</td>\n",
       "      <td>303.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>131.6873</td>\n",
       "      <td>338.2</td>\n",
       "      <td>64.57</td>\n",
       "      <td>382.2</td>\n",
       "      <td>474.9</td>\n",
       "      <td>0.188</td>\n",
       "      <td>181.00</td>\n",
       "      <td>35.4072</td>\n",
       "      <td>632.8</td>\n",
       "      <td>76.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125538</td>\n",
       "      <td>-0.060258</td>\n",
       "      <td>-0.178902</td>\n",
       "      <td>1.145780</td>\n",
       "      <td>-0.001495</td>\n",
       "      <td>1.65756</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.002743</td>\n",
       "      <td>300.065</td>\n",
       "      <td>302.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-11</th>\n",
       "      <td>131.7082</td>\n",
       "      <td>121.5</td>\n",
       "      <td>22.22</td>\n",
       "      <td>377.4</td>\n",
       "      <td>456.5</td>\n",
       "      <td>0.184</td>\n",
       "      <td>20.15</td>\n",
       "      <td>36.9236</td>\n",
       "      <td>244.3</td>\n",
       "      <td>29.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093371</td>\n",
       "      <td>-0.060537</td>\n",
       "      <td>-0.161396</td>\n",
       "      <td>0.638123</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>1.20892</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.002318</td>\n",
       "      <td>299.410</td>\n",
       "      <td>299.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DOY   SWin   SWout   LWin  LWout     Rr      Rn       RH  \\\n",
       "date                                                                        \n",
       "2023-05-11  131.6249  695.4  135.20  398.9  507.4  0.194  451.60  35.8238   \n",
       "2023-05-11  131.6457  506.8   96.70  392.3  497.4  0.187  305.10  35.3730   \n",
       "2023-05-11  131.6665  319.4   60.97  395.8  477.3  0.190  177.00  35.6585   \n",
       "2023-05-11  131.6873  338.2   64.57  382.2  474.9  0.188  181.00  35.4072   \n",
       "2023-05-11  131.7082  121.5   22.22  377.4  456.5  0.184   20.15  36.9236   \n",
       "\n",
       "              PPFD   PPFDr  ...        ET   (z-d)/L        T*     v_var  \\\n",
       "date                        ...                                           \n",
       "2023-05-11  1340.0  160.80  ...  0.159395 -0.104409 -0.343706  1.337320   \n",
       "2023-05-11   982.0  118.10  ...  0.178391 -0.170200 -0.443938  1.958010   \n",
       "2023-05-11   622.6   74.94  ...  0.147962 -0.099141 -0.290778  2.165070   \n",
       "2023-05-11   632.8   76.32  ...  0.125538 -0.060258 -0.178902  1.145780   \n",
       "2023-05-11   244.3   29.03  ...  0.093371 -0.060537 -0.161396  0.638123   \n",
       "\n",
       "            w/co2_cov  w/h2o_cov  w/ch4_cov      FCH4       Ta      Tc  \n",
       "date                                                                    \n",
       "2023-05-11  -0.004358    2.03306  -0.000042 -0.002199  300.282  308.48  \n",
       "2023-05-11  -0.006526    2.25563  -0.000043  0.002734  300.194  306.58  \n",
       "2023-05-11  -0.004225    1.91322  -0.000033 -0.000904  299.926  303.04  \n",
       "2023-05-11  -0.001495    1.65756  -0.000024 -0.002743  300.065  302.43  \n",
       "2023-05-11  -0.001278    1.20892  -0.000020 -0.002318  299.410  299.08  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclude non-numeric predictors\n",
    "ts_data_numeric = ts_data.select_dtypes(include=['float64', 'int64'])\n",
    "ts_data_numeric.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49c05e",
   "metadata": {},
   "source": [
    "Transforming the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981c7f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and target\n",
    "X = ts_data_numeric.drop(columns=['FCH4'])\n",
    "y = ts_data_numeric['FCH4']\n",
    "\n",
    "# Scaling data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5b2f86",
   "metadata": {},
   "source": [
    "Train Test Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3c73a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronological Splitting\n",
    "train_size = int(len(X_scaled) * 0.7)\n",
    "val_size = int(len(X_scaled) * 0.2)\n",
    "\n",
    "X_train, X_val, X_test = X_scaled[:train_size], X_scaled[train_size:train_size+val_size], X_scaled[train_size+val_size:]\n",
    "y_train, y_val, y_test = y_scaled[:train_size], y_scaled[train_size:train_size+val_size], y_scaled[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d1ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'RMSE': rmse, 'MSE': mse, 'MAE': mae, 'MAPE': mape, 'R2': r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6552033d",
   "metadata": {},
   "source": [
    "1-step ahead Forecasting using FC, RNN, and LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e072b1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34580d9a0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fully Connected Feed Forward Networks\n",
    "# Model 1: Single hidden layer\n",
    "\n",
    "# Fully Connected Networks\n",
    "model_fc1 = Sequential([Input(shape=(X_train.shape[1],)), Dense(26, activation='relu'), Dense(1)])\n",
    "model_fc1.compile(optimizer='adam', loss='mse')\n",
    "model_fc1.fit(X_train, y_train, epochs=30, batch_size=13, validation_data=(X_val, y_val), verbose=0)\n",
    "\n",
    "model_fc2 = Sequential([Input(shape=(X_train.shape[1],)), Dense(52, activation='relu'), Dense(26, activation='relu'), Dense(1)])\n",
    "model_fc2.compile(optimizer='adam', loss='mse')\n",
    "model_fc2.fit(X_train, y_train, epochs=30, batch_size=13, validation_data=(X_val, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bbd83f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x347478f80>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple RNN\n",
    "X_train_rnn = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_val_rnn = X_val.reshape(X_val.shape[0], 1, X_val.shape[1])\n",
    "X_test_rnn = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "model_rnn1 = Sequential([Input(shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])), SimpleRNN(26, activation='relu'), Dense(1)])\n",
    "model_rnn1.compile(optimizer='adam', loss='mse')\n",
    "model_rnn1.fit(X_train_rnn, y_train, epochs=30, validation_data=(X_val_rnn, y_val), verbose=0)\n",
    "\n",
    "model_rnn2 = Sequential([Input(shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])), SimpleRNN(52, activation='relu'), Dense(26, activation='relu'), Dense(1)])\n",
    "model_rnn2.compile(optimizer='adam', loss='mse')\n",
    "model_rnn2.fit(X_train_rnn, y_train, epochs=30, validation_data=(X_val_rnn, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2cfa1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3497b2930>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Models\n",
    "\n",
    "# LSTM Model 1\n",
    "model_lstm1 = Sequential([Input(shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])), LSTM(26, activation='relu'), Dense(1)])\n",
    "model_lstm1.compile(optimizer='adam', loss='mse')\n",
    "model_lstm1.fit(X_train_rnn, y_train, epochs=30, validation_data=(X_val_rnn, y_val), verbose=0)\n",
    "\n",
    "# LSTM Model 2\n",
    "model_lstm2 = Sequential([Input(shape=(X_train_rnn.shape[1], X_train_rnn.shape[2])), LSTM(52, activation='relu'), Dense(26, activation='relu'), Dense(1)])\n",
    "model_lstm2.compile(optimizer='adam', loss='mse')\n",
    "model_lstm2.fit(X_train_rnn, y_train, epochs=30, validation_data=(X_val_rnn, y_val), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a784f8b",
   "metadata": {},
   "source": [
    "Results of 1 step forecasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abb8a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions and Evaluations\n",
    "results_1step = []\n",
    "for name, model, data in zip(\n",
    "    ['FC1', 'FC2', 'RNN1', 'RNN2', 'LSTM1', 'LSTM2'],\n",
    "    [model_fc1, model_fc2, model_rnn1, model_rnn2, model_lstm1, model_lstm2],\n",
    "    [X_test, X_test, X_test_rnn, X_test_rnn, X_test_rnn, X_test_rnn]\n",
    "):\n",
    "    y_pred = model.predict(data)\n",
    "    y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "    metrics = evaluate_model(y_test_inv, y_pred_inv)\n",
    "    metrics['Model'] = name\n",
    "    results_1step.append(metrics)\n",
    "\n",
    "results_1step_df = pd.DataFrame(results_1step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "413f34f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-step Forecasting Results:  \n",
      "        RMSE       MSE       MAE       MAPE        R2  Model\n",
      "0  0.023194  0.000538  0.017347  14.820231  0.315923    FC1\n",
      "1  0.018538  0.000344  0.014155  33.177009  0.563007    FC2\n",
      "2  0.052967  0.002806  0.039490  48.491303 -2.567633   RNN1\n",
      "3  0.029765  0.000886  0.018144  13.865378 -0.126649   RNN2\n",
      "4  0.029219  0.000854  0.018078  17.806238 -0.085673  LSTM1\n",
      "5  0.027299  0.000745  0.023026  39.415203  0.052334  LSTM2\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print('1-step Forecasting Results: ', '\\n',results_1step_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e2b317",
   "metadata": {},
   "source": [
    "Overall, the LSTM model performed better than the fully connected network and the recurrent neural network.\n",
    "\n",
    "The RNN (Recurrent Neural Network) performed better than the FC (Fully Connected network) which can imply that the recurrent connection enables it to better capture the temporal dependencies of the data as desired from the architectural intuition of the RNN.\n",
    "\n",
    "The LSTM (Long Short Term Memory) performed better than the RNN (Recurrent Neural Network) which can imply that the forget gate is able to exclude the unnecessary information enabling it to better capture the temporal dependency by there by solving the issue of the vanishing/ exploding gradients in RNN over a long period of time.\n",
    "\n",
    "Note that these inferences can be viable as the same architectural parameters (number of units) were used for comparing these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd2863",
   "metadata": {},
   "source": [
    "3-step ahead forecasting with RNN and LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bd0f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected 3-step ahead forecasting setup\n",
    "steps_ahead = 3\n",
    "X_multi, y_multi = [], []\n",
    "for i in range(len(X_scaled) - 2*steps_ahead):\n",
    "    X_multi.append(X_scaled[i:i+steps_ahead, :])\n",
    "    y_multi.append(y_scaled[i+steps_ahead:i+2*steps_ahead, 0])\n",
    "\n",
    "X_multi, y_multi = np.array(X_multi), np.array(y_multi)\n",
    "\n",
    "train_size_multi = int(len(X_multi)*0.7)\n",
    "val_size_multi = int(len(X_multi)*0.2)\n",
    "\n",
    "X_train_m, X_val_m, X_test_m = X_multi[:train_size_multi], X_multi[train_size_multi:train_size_multi+val_size_multi], X_multi[train_size_multi+val_size_multi:]\n",
    "y_train_m, y_val_m, y_test_m = y_multi[:train_size_multi], y_multi[train_size_multi:train_size_multi+val_size_multi], y_multi[train_size_multi+val_size_multi:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c90bede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31cc32930>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model for 3-step ahead\n",
    "model_rnn3 = Sequential([\n",
    "    Input(shape=(X_train_m.shape[1], X_train_m.shape[2])),\n",
    "    SimpleRNN(128, activation='relu', return_sequences=True),\n",
    "    SimpleRNN(64, activation='relu'),\n",
    "    Dense(steps_ahead)\n",
    "])\n",
    "model_rnn3.compile(optimizer='adam', loss='mse')\n",
    "model_rnn3.fit(X_train_m, y_train_m, epochs=30, validation_data=(X_val_m, y_val_m), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3364c7e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31d27f290>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM Model for 3-step ahead\n",
    "model_lstm3 = Sequential([\n",
    "    Input(shape=(X_train_m.shape[1], X_train_m.shape[2])),\n",
    "    LSTM(128, activation='relu', return_sequences=True),\n",
    "    LSTM(64, activation='relu'),\n",
    "    Dense(steps_ahead)\n",
    "])\n",
    "model_lstm3.compile(optimizer='adam', loss='mse')\n",
    "model_lstm3.fit(X_train_m, y_train_m, epochs=30, validation_data=(X_val_m, y_val_m), verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da08bb",
   "metadata": {},
   "source": [
    "Results for 3 step prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d22680e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and Display Results\n",
    "results_3step = []\n",
    "for name, model in zip(['RNN_3step', 'LSTM_3step'], [model_rnn3, model_lstm3]):\n",
    "    y_pred = model.predict(X_test_m)\n",
    "    y_pred_inv = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_inv = scaler_y.inverse_transform(y_test_m)\n",
    "    metrics = evaluate_model(y_test_inv.flatten(), y_pred_inv.flatten())\n",
    "    metrics['Model'] = name\n",
    "    results_3step.append(metrics)\n",
    "\n",
    "results_3step_df = pd.DataFrame(results_3step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d195c309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-step Forecasting Results: \n",
      "        RMSE       MSE       MAE       MAPE        R2       Model\n",
      "0  0.060318  0.003638  0.046163  74.166938 -3.564378   RNN_3step\n",
      "1  0.036506  0.001333  0.025350  33.345497 -0.671908  LSTM_3step\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print('3-step Forecasting Results:', '\\n',results_3step_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4542eb",
   "metadata": {},
   "source": [
    "Overall, the LSTM model performed better than the recurrent neural network in 3-step forecasting.\n",
    "\n",
    "The LSTM (Long Short Term Memory) performed better than the RNN (Recurrent Neural Network) which can imply that the forget gate is able to exclude the unnecessary information enabling it to better capture the temporal dependency by there by solving the issue of the vanishing/ exploding gradients in RNN over a long period of time.\n",
    "\n",
    "Note that these inferences can be viable as the same architectural parameters (number of units) were used for comparing these models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
